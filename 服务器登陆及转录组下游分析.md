1.Easyconnect
账户：xiongxianpeng
密码:xxp#199208

服务器
#可视化软件WinSCP
192.168.1.23
账户：xiongxianpeng
密码：agis#2020

ip:192.168.1.23   端口22
账户：xiongxianpeng
密码：agis#2020


1. 数据下载：
登录https://sra-explorer.info/# ——输入SRR号-选择样本-add number(样本数) to collection-number saved datasets- Aspera commands for downloading FastQ files(复制里面的内容)
#进入rnaseq环境
#ssh io9 （数据下载需要使用io9这个节点）
conda activate rnaseq 
cd /vol3/agis/huguanjing_group/xiongxianpeng/zhong113/drought
建立相应文件夹 mkdir rawdata, cleandata, 

vi download.sh
把这些复制过来(#!/usr/bin/env bash
ascp -QT -l 300m -P33001 -i $HOME/.aspera/connect/etc/asperaweb_id_dsa.openssh era-fasp@fasp.sra.ebi.ac.uk:vol1/fastq/SRR120/012/SRR12077612/SRR12077612_1.fastq.gz . && mv SRR12077612_1.fastq.gz SRR12077612_LfJ02-508-3DPA1_1.fastq.gz
)

nohup bash download.sh &
####我只会后台提交，qsub各种报错；一个大概需要十几分钟就下载完了

2. #数据质控
vi fq.sh
qcdir=/vol3/agis/huguanjing_group/xiongxianpeng/27Sample/second/fq         
# qcdir（质控结果输出位置）
fqdir=/vol3/agis/huguanjing_group/xiongxianpeng/27Sample/second/rawdata   
# fqdir(rawdata文件夹)
fastqc -t 3 -o $qcdir $fqdir/*.fastq.gz
#############################fastqc软件可能需要加绝对路径  /vol3/agis/huguanjing_group/xiongxianpeng/miniconda3/bin/fastqc
qsub fq.sh 
查看是否运行：qstat -u xiongxianpeng
杀死任务：qdel 任务名称


#fastp数据过滤
# 获取ID名称  
ls *gz|sed 's/_2.fastq.gz//g'|sed 's/_1.fastq.gz//g'|uniq|>3sample.txt

vi fastp.sh

while read line
do
clean=/vol3/agis/huguanjing_group/xiongxianpeng/salt2023/rawdata/clean
#过滤后输出文件位置
raw=/vol3/agis/huguanjing_group/xiongxianpeng/salt2023/rawdata
#rawdata位置
read1=${line}_1.fastq.gz
read2=${line}_2.fastq.gz
fastp -w 8 -i $raw/$read1 \
-I $raw/$read2 \
-o $clean/${line}_1.clean.gz \
-O $clean/${line}_2.clean.gz \
-l 15 -q 15 --compression=6 -R $cleandata/${line} \
-h $clean/${line}.fastp.html \
-j $clean/${line}.fastp.json
done < /vol3/agis/huguanjing_group/xiongxianpeng/salt2023/rawdata/3sample.txt  #样本名称
qsub fastp.sh 


#############fastp绝对路径：/vol3/agis/huguanjing_group/xiongxianpeng/miniconda3/bin/fastp

#批量输出数据Q20/Q30/GC等结果
grep -n "total_reads"  *.json|grep 'json:4'|sed 's/.fastp.json:4://g'|sed 's/_/\t/g'>allread.txt
grep -n "total_reads"  *.json|grep 'json:14'|sed 's/.fastp.json:4://g'|sed 's/_/\t/g'>clean.read.txt
grep 'gc_content' *.json|sed '1~2d' |sed 's/"gc_content"://g'>gc.txt
grep 'q20_rate' *.json|sed '1~2d' |sed 's/"q20_rate"://g'>q20.txt
grep 'q30_rate' *.json|sed '1~2d' |sed 's/"q30_rate"://g'>q30.txt
grep 'total_bases' *.json|sed '1~2d' |awk '!(NR%2)'| sed 's/"total_bases"://g'>clean.base.txt

ls *unique.bam|sed 's/.unique.bam//g'|sed 's/_/\t/g'>sample.txt
le hisat.11.sh.e1378305 |grep 'reads; of these'|sed 's/ /\t/g'>read.txt
le hisat.11.sh.e1378305 |grep 'aligned exactly 1 time'|sed 's/ /\t/g'>unique.txt


########Ga
#Hisat2构建索引
hisat2-build Ghirsutum_527_v2.0.fa Ghirsutum_527_v2.0   # 棉花需要1h 
#直接交互跑就行，你不需要做这步

#单个样本比对
vi hisat1.sh
while read line
do
index=/vol3/agis/huguanjing_group/xiongxianpeng/fiberData/UTXgenome/Ghirsutum_527_v2.0
#index为索引，不需要修改
inputdir=/vol3/agis/huguanjing_group/xiongxianpeng/salt2023/rawdata/clean
#inputdir 过滤后的数据位置
outdir=/vol3/agis/huguanjing_group/xiongxianpeng/salt2023/rawdata/hisat
##outdir输出结果位置
read1=${line}_1.clean.gz
read2=${line}_2.clean.gz
hisat2 -p 10 -x $index -1 $inputdir/$read1 -2 $inputdir/$read2 -S ${outdir}/${line}.Hisat_aln.sam
#sam杞琤am
/vol3/agis/huguanjing_group/xiongxianpeng/miniconda3/envs/rnaseq/bin/samtools sort -@ 3 -o ${outdir}/${line}.Hisat_aln.sorted.bam ${outdir}/${line}.Hisat_aln.sam
/vol3/agis/huguanjing_group/xiongxianpeng/miniconda3/envs/rnaseq/bin/samtools view -bhF 12 -q 30 ${outdir}/${line}.Hisat_aln.sorted.bam >${outdir}/${line}.unique.bam
/vol3/agis/huguanjing_group/xiongxianpeng/miniconda3/envs/rnaseq/bin/samtools index ${outdir}/${line}.unique.bam ${outdir}/${line}.unique.bam.bai>${line}.log
/vol3/agis/huguanjing_group/xiongxianpeng/miniconda3/envs/rnaseq/bin/samtools flagstat -@ 3 ${outdir}/${line}.unique.bam > ${outdir}/${line}.txt
rm ${outdir}/${line}.Hisat_aln.sam
rm ${outdir}/${line}.Hisat_aln.sorted.bam
done < /vol3/agis/huguanjing_group/xiongxianpeng/salt2023/rawdata/3sample.txt  #样本名称



#### 7.表达定量  获得每个基因的count,用于DESEQ2
##### 7.1 featureCounts (Version 2.0.1，-p双端 -t外显子 )
## vi feature.sh
inputdir=/vol3/agis/huguanjing_group/xiongxianpeng/fiberData/AllBam

#inputdir：bam文件位置
gtf=/vol3/agis/huguanjing_group/xiongxianpeng/fiberData/AllBam/feature/Ghirsutum_527_v2.1.gene_exons.primaryOnly.gff3
#gtf这个位置不变
vi feature.sh
featureCounts -T 10 -p -t CDS -g gene_id -a $gtf -o all.id.txt $inputdir/*.unique.bam
qsub feature.sh
# 对定量结果质控
multiqc all.id.txt.summary
#去掉样品名称的前缀
sed -i 's#/vol3/agis/huguanjing_group/xiongxianpeng/fiberData/251samples/hisat2/##g' all.id.txt
#去掉样品名称的后缀
sed -i 's#_*##g' all.id.txt
# 删除每一行以某个字符开头的子字符串
sed 's/*_//'txt.txt
sed -r 's/.*({7}.)/\1/' txt.txt
#去掉第一行（注释行）q
less -S all2.id.txt |grep -v '#' >all.id.txt
# 得到表达矩阵
cat all.id.txt | cut -f1,7- > counts1.txt
、
#8.1. 估计表达丰度（4 mins per sample）
while read line
do
sam=/vol3/agis/huguanjing_group/xiongxianpeng/zhong113/Hista2
stringtie -e -B -p 8 -G /vol3/agis/huguanjing_group/xiongxianpeng/fiberData/UTXgenome/gff3/Ghirsutum_527_v2.1.gene_exons.primaryOnly.gff3 
-o /vol3/agis/huguanjing_group/xiongxianpeng/zhong113/stringtie/${line}/${line}.gtf ${sam}/${line}
done </vol3/agis/huguanjing_group/xiongxianpeng/zhong113/rawdata1/48.sampmel.txt

#8.2  Obtain TPM and FPKM:
while read line
do
bam=/vol3/agis/huguanjing_group/xiongxianpeng/zhong113/stringtie
grep 'TPM' ${bam}/${line}/${line}.gtf |grep 'Goh'|cut -f 9|grep 'TPM'|awk '{print $4$10}'| sed 's/;/\t/g'|less -S> ${bam}/${line}.txt
done </vol3/agis/huguanjing_group/xiongxianpeng/zhong113/rawdata1/48.sample.txt
#获得带有基因id的行
#while read line
#do
#bam=/vol3/agis/huguanjing_group/xiongxianpeng/27Sample/ball
#grep 'Goh' ${bam}/${line}.txt |less -S> ${bam}/${line}-1.txt
#done </vol3/agis/huguanjing_group/xiongxianpeng/27Sample/272.txt 
5.对每个文件排序
while read line
do
TPM=/vol3/agis/huguanjing_group/xiongxianpeng/zhong113/TPM
sort -n ${TPM}/${line}.txt > ${TPM}/${line}_TPM.sort.txt 
done < /vol3/agis/huguanjing_group/xiongxianpeng/zhong113/rawdata1/48sample.txt

6. 合并文件
#获得每个样本基因列表
ls *sort.txt >list.txt
for i in `cat list.txt`;do cut -f2 $i >$i.tmp;done
paste -s *.tmp> all.txt
#获得基因列表
le DP8400023063BR_L01_38.unique.bam_TPM.sort.txt|cut -f 1 > a.txt
le a.txt|tr "\n" ","|sed -e 's/,$/\n/'|sed 's/,/\t/g'>aa.txt
cat  aa.txt all.txt >all.tpm.txt
paste  sample.txt all.tpm.txt (sample +gene)





下游分析PCA,GO,KEGG,WGCNA

#########PCA###################
rm(list=ls())
#清空环境变量
setwd("C:/Users/hr345/Desktop/PRJNA919499")
exprSetTPM=read.table('finally2.txt',header=T,sep="\t",row.names=1)
dim(exprSetTPM)
# [1] 40960  1005
#meta=a[,1:6]   #基因信息
data_t <- t(exprSetTPM)
dim(data_t)
rownames(data_t)
expres1.1=data_t
#write.csv(expres1.1,"expe.48.csv",sep="\t")
# 基因表达量在所有样本中均大于1
keep=rowSums(expres1.1>1) >= floor(1*ncol(expres1.1))
table(keep)
# FALSE  TRUE 
# 45318 30058 
count1 <- expres1.1[keep,]
dim(count1)
#[1] 30058  1005
anno=read.table("36sample2.txt",header=T,sep="\t")
head(anno)
# DPA   Accession
#5 DPA     TM-1
#8 DPA      TM-1×中棉11

###PCA analysis

library(ggplot2)
df_pca <- prcomp(log2(t(count1)+1)) #计算主成分
dim(count1)
#[1] 22907  1005
anno$Salt<- factor(anno$Salt, levels=c("CK","SK","S"), ordered=TRUE)
anno$time<- factor(anno$time, levels=c("1h","6h","12h","24h"), ordered=TRUE)
df_pcs <-data.frame(df_pca$x,time = anno$time,Salt=anno$Salt)   

#df_pcs <-data.frame(df_pca$x,Salt=anno$Salt)  
head(df_pcs,3)  #查看主成分结果
plot(df_pca$x[,1], df_pca$x[,2])
#pdf("pca.log2norm413.pdf") #可以单独画画
ggplot(df_pcs,aes(x=PC1,y=PC2,color=time,shape=Salt))+ geom_point()

percentage<-round(df_pca$sdev / sum(df_pca$sdev) * 100,2)
percentage<-paste(colnames(df_pcs),"(", paste(as.character(percentage), "%", ")", sep=""))

ggplot(df_pcs,aes(x=PC1,y=PC2,color=time,shape=Salt))+
  geom_point(size=5, alpha = 1/2)+ 
  xlab(percentage[1]) +
  ylab(percentage[2])+
  theme(plot.title = element_text(size = 1, face = "bold") ,legend.title=element_text(size=10), 
        legend.text=element_text(size=10)) +theme(axis.title.x = element_text(size = 20)) +
  theme(axis.title.y = element_text(size = 20))+ scale_color_manual(values=c("#DE7E73", "#8EC0E4","#60c5ba","#6a60a9"))+ scale_shape_manual(values = c(15,16,17))+
  labs(subtitle = "PRJNA919499 PCA")
#
#700 600

#########tSNE###################
expr1_unique<-unique(t(count1))
dim(expr1_unique)
class(expr1_unique)
#[1]    73 75376
library(Rtsne)
tsne_out = Rtsne(expr1_unique,perplexity=10)
str(tsne_out)
pdat = data.frame(tsne_out$Y)
pdat=cbind(pdat,anno$Salt,anno$time)

colnames(pdat) = c("tSNE_1","tSNE_2","Salt","time")
head(pdat)
pdat$Salt<- factor(pdat$Salt, levels=c("CK", "SK", "S"), ordered=TRUE)
pdat$time<- factor(pdat$time, levels=c("1h", "6h", "12h","24h"), ordered=TRUE)
library(ggplot2)
ggplot(pdat,aes(x=tSNE_1,y=tSNE_2,color=time,shape=Salt))+
  geom_point(size=3)+ 
  theme(plot.title = element_text(size = 1, face = "bold") ,legend.title=element_text(size=20), 
        legend.text=element_text(size=20)) +theme(axis.title.x = element_text(size = 20)) +
  theme(axis.title.y = element_text(size = 20))+ 
  scale_color_manual(values=c("#DE7E73", "#8EC0E4","#60c5ba","#6a60a9"))+
  scale_shape_manual(values = c(15,16,17))+
  labs(subtitle = "PRJNA919499 tSEN")

########UMAP####################
library(umap)
#expr1=t(expr)
dim(expr1_unique)
# 使用umap函数进行UMAP降维分析
iris.umap = umap::umap(expr1_unique)
# 查看降维后的结果
head(iris.umap$layout)
##           [,1]     [,2]
#SRR10426360 -3.447716 1.967124
#SRR10426373 -3.613967 2.087851
#SRR12077547 -4.925000 3.021000
#SRR12077573 -4.894924 2.986124
# 使用plot函数可视化UMAP的结果]
pumap = data.frame(iris.umap$layout)
pumap=cbind(pumap,anno$Salt,anno$time)
colnames(pumap) = c("UMAP_1","UMAP_2","Salt","time")
rownames(pumap)=anno$SRR
rownames(pdat)=anno$SRR
head(pumap)
pumap$Salt<- factor(pumap$Salt, levels=c("CK", "S", "SK"), ordered=TRUE)
pumap$time<- factor(pumap$time, levels=c("1h", "6h", "12h","24h"), ordered=TRUE)
ggplot(pumap,aes(UMAP_1,UMAP_2,color=time,shape=Salt))+
  geom_point(size=3)+ 
  theme(plot.title = element_text(size = 1, face = "bold") ,legend.title=element_text(size=10), 
        legend.text=element_text(size=10)) +theme(axis.title.x = element_text(size = 13)) +
  theme(axis.title.y = element_text(size = 13))+
  scale_color_manual(values=c("#DE7E73", "#8EC0E4","#60c5ba","#6a60a9"))+
  scale_shape_manual(values = c(15,16,17))+
  labs(subtitle = "PRJNA919499 UMAP")

write.csv(pumap,"pumap.csv")

write.csv(pdat,"pdat.csv")


####################GO,KEGG################
rm(list = ls())
setwd("C:/E盘/博士后第一个项目/KEGG和GO代码/final")
library(stringr)
library(dplyr)
library(tidyverse)
library(stringr)
library(KEGGREST)
library(AnnotationForge)
#GO analysis
egg_f <- "Ghirsutum_527_v2.1.protein_xxp.annotations"
#xuezhu帮我做的
egg1 <- read.csv(egg_f, sep = "\t")
dim(egg1)
#[1] 101038     22
gene75736<-read.table("75736.txt", sep = "\t",header = T)
head(gene75736)
#query_name
#1 Gohir.1Z001700.1
egg75736=merge(gene75736,egg1,by="query_name")
egg<-egg75736

#效率高的方法
gene_ids <- egg$query_name
eggnog_lines_with_go <- egg$GOs!= ""
eggnog_lines_with_go
eggnog_annoations_go <- str_split(egg[eggnog_lines_with_go,]$GOs, ",")
gene_to_go <- data.frame(gene = rep(gene_ids[eggnog_lines_with_go],
                                    times = sapply(eggnog_annoations_go, length)),
                         term = unlist(eggnog_annoations_go))
head(gene_to_go)
# gene       term
#1 Gohir.1Z015700.1 GO:0005575
#2 Gohir.1Z015700.1 GO:0005622
dim(gene_to_go)
#[1] 2035409       2
save(gene_to_go,file = "GO.RData")
#load(file = "GO.RData")
#

library(clusterProfiler)
gene_list<-gene75736$query_name[1:2000]
term2gene<-gene_to_go[,c(2,1)]
df<-enricher(gene=gene_list,
             pvalueCutoff = 0.05,
             pAdjustMethod = "BH",
             TERM2GENE = term2gene)
head(df)
barplot(df)
dotplot(df)
df<-as.data.frame(df)
head(df)
dim(df)
df1<-go2term(df$ID)
dim(df1)
head(df1)
class(df1)
names(df1) <- c("ID","term")
dff=merge(df1,df,by="ID")
#将dff的替换df
dff$term<-df1$term
df2<-go2ont(dff$ID)
dim(df2)
head(df2)
dff$Ont<-df2$Ontology
head(dff)
#write.table(dff,"dff.GO.txt",sep = "\t")

df3<-dff%>%
  select(c("term","Ont","pvalue"))
head(df3)
library(ggplot2)
ggplot(df3,aes(x=term,y=-log10(pvalue)))+
  geom_col(aes(fill=Ont))+
  coord_flip()+labs(x="")+
  theme_bw()


#KEGG
library(stringr)
library(dplyr)
library(clusterProfiler)

#json提取
if(!file.exists('kegg_info.RData')){
  library(jsonlite)
  library(purrr)
  library(RCurl)
  update_kegg <- function(json = "ko00001.json",file=NULL) {
    pathway2name <- tibble(Pathway = character(), Name = character())
    ko2pathway <- tibble(Ko = character(), Pathway = character())
    kegg <- fromJSON(json)
    for (a in seq_along(kegg[["children"]][["children"]])) {
      A <- kegg[["children"]][["name"]][[a]]
      for (b in seq_along(kegg[["children"]][["children"]][[a]][["children"]])) {
        B <- kegg[["children"]][["children"]][[a]][["name"]][[b]] 
        for (c in seq_along(kegg[["children"]][["children"]][[a]][["children"]][[b]][["children"]])) {
          pathway_info <- kegg[["children"]][["children"]][[a]][["children"]][[b]][["name"]][[c]]
          pathway_id <- str_match(pathway_info, "ko[0-9]{5}")[1]
          pathway_name <- str_replace(pathway_info, " \\[PATH:ko[0-9]{5}\\]", "") %>% str_replace("[0-9]{5} ", "")
          pathway2name <- rbind(pathway2name, tibble(Pathway = pathway_id, Name = pathway_name))
          kos_info <- kegg[["children"]][["children"]][[a]][["children"]][[b]][["children"]][[c]][["name"]]
          kos <- str_match(kos_info, "K[0-9]*")[,1]
          ko2pathway <- rbind(ko2pathway, tibble(Ko = kos, Pathway = rep(pathway_id, length(kos))))
        }
      }
    }
    save(pathway2name, ko2pathway, file = file)
  }
  update_kegg(json = "ko00001.json",file="kegg_info.RData")
}
load("kegg_info.RData")



egg[egg==""]<-NA
gene2ko <- egg %>%
  dplyr::select(GID = query_name, Ko = KEGG_ko) %>%
  na.omit()
head(gene2ko)
# GID        Ko
#1  Gohir.1Z001700.1 ko:K03327
#8  Gohir.1Z049301.1 ko:K09422
gene2ko[,2]<-gsub("ko:","",gene2ko[,2])
head(gene2ko)
names(gene2ko) <- c("GID","Ko")

kegg_l <- read.table("ko.pathway.name.lst", sep = "\t", header = TRUE)

pathway2gene <- gene2ko %>% left_join(ko2pathway, by = "Ko") %>%
  dplyr::select(pathway=Pathway,gene=GID) %>%
  na.omit()

head(pathway2gene)
pathway2name=kegg_l[,2:3]
head(pathway2name)
pathway2name =pathway2name[!duplicated(pathway2name$Pathway), ]

gene_list<-gene75736$query_name[1:3000]
df<-enricher(gene=gene_list,
             pvalueCutoff = 0.05,
             pAdjustMethod = "BH",
             TERM2GENE = pathway2gene,
             TERM2NAME = pathway2name)
dim(df)
head(df)
dotplot(df)
barplot(df)

####WGCNA####


















